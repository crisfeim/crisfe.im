---
title: Haciendo sufrir a la inteligencia artificial en tu lugar
date: 2025-05-13
slug: making-the-ai-suffer-so-you-dont-have-to
og-image: images/system.png
---

Hace poco [reescrib√≠](https://github.com/crisfeim/cli-tddbuddy) un mini-experimento que ten√≠a empolvado desde hace unos meses.

Se trata de un esfuerzo por implementar un mecanismo de generaci√≥n de c√≥digo con control de calidad automatizado.

En este art√≠culo quiero compartir los resultados.

## Idea

Como desarrollador, mis interacciones con la *IA* se pueden reducir a un bucle:

A partir de un prompt inicial, pido al modelo que genere c√≥digo *(1)*.<br>Lo pruebo en un entorno de desarrollo *(2)*[^nosiempre]. Si falla *(3)*, envio el error al modelo para darle feedback y regenere el c√≥digo.

[^nosiempre]: Esto no es siempre necesario, muchas veces se puede ver de un vistazo si el c√≥digo generado est√° bien o mal.

Repito hasta que el c√≥digo generado funcione.

<pre class="emoji-diagram">
     ‚ï≠‚îÄ‚Ä∫ üë®‚Äçüíª  ‚îÄ‚ïÆ
üë®‚Äçüíª ‚Üí ü§ñ       ‚öôÔ∏è
     ‚ï∞‚îÄ  üë®‚Äçüíª ‚Äπ‚îÄ‚ïØ
</pre>

Me di cuenta de que pod√≠a eliminarme de la ecuaci√≥n, concretamente, de los pasos 2 y 3:

<pre class="emoji-diagram">
     ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
üë®‚Äçüíª ‚Üí ü§ñ    ‚öôÔ∏è
     ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
</pre>

Mi ~~fantas√≠a~~ idea era lograr un flujo en el que mi trabajo se convirtiese en escribir *specs*, darle al bot√≥n de ejecuci√≥n, irme a tomar un caf√© y a vivir la vida y volver 3 horas despu√©s para encontrarme el trabajo hecho.

Se me ocurri√≥[^1] una idea sencilla: un bucle automatizado basado en un enfoque dirigido por pruebas unitarias[^tdd]

[^tdd]: *Test Driven Development*

Usando una prueba initaria de un sistema sin implementar como *prompt*[^prompt], puedo pedirle al modelo que deduzca la implementaci√≥n del sistema.

[^prompt]: Instrucci√≥n inicial

Por ejemplo, usando esta prueba como *prompt*:

```swift
func test_adder() {
  let sut = Adder(1,3)
  XCTAssertEqual(sut.result, 4)
}
```

El modelo puede generar algo como esto:

```swift
struct Adder {
  let result: Int
  init(_ a: Int, _ b: Int) {
    result = a + b
  }
}
```

Este formato de *prompt* permite que el modelo (ü§ñ) "comunique" directamente con el entorno de ejecuci√≥n (‚öôÔ∏è), automatizando la verificaci√≥n del c√≥digo y el env√≠o de feedback.

Si el c√≥digo generado es inv√°lido o no pasa la prueba, el ciclo se repite. Si el c√≥digo es v√°lido, salimos del ciclo.

<video id="v1" autoplay muted loop playsinline  style="width: 100%; height: auto;" aria-hidden="true">
  <source src="videos/flow.mp4" type="video/mp4">
  Tu navegador no soporta el video HTML5.
</video>


## Automatizaci√≥n

El enfoque *naive* que us√© consisti√≥ en usar el m√©todo `assert` de *Swift*, como *framework* de testing:

```swift
func test_adder() {
  let sut = Adder(1,3)
  assert(sut.result == 4)
}
```

*Assert* lanza un *trap* en tiempo de ejecuci√≥n cuando la condici√≥n es falsa, generando salida por *stderr* [^debug], lo que lo hace √∫til como se√±al de error para este sistema.

[^debug]: En *builds* de *debug*

Para ejecutar las pruebas unitarias no utilizo ning√∫n mecanismo complejo, simplemente las invoco en las propias especificaciones:

```swift
func test_adder() {
  let sut = Adder(1,3)
  assert(sut.result == 4)
}

test_adder()
```

Para probar si el c√≥digo generado pasa las pruebas, los concateno en una √∫nica cadena de texto que almaceno en un archivo temporal[^8] para pasarla al compilador de Swift[^process].

```swift
let concatenated = generatedCode + " " + unitTestsSpecs
let tmpFileURL = tmFileURLWithTimestamp("generated.swift")
swiftRunner.runCode(at: tmpFileURL)
```

[^process]: Invocado con la *api* *Procress*. [Implementaci√≥n](https://github.com/crisfeim/cli-tddbuddy/blob/main/Sources/Core/Infrastructure/SwiftRunner.swift).

Si el proceso devuelve un c√≥digo de salida distinto de cero, significa que la ejecuci√≥n del c√≥digo fall√≥. En ese caso, repito el ciclo hasta que el c√≥digo sea cero:

```swift
var output = swiftRunner.runCode(at: tmpFileURL)
while output.processResult.exitCode != 0 {
    let regeneratedCodeFileURL = ...
    output = swiftRunner.runCode(at: regeneratedCodeFileURL)
}
```

<!-- >
## Dise√±o

Inicialmente plante√© tres componentes:

1. ü§ñ *Client*: Genera c√≥digo a partir de las specs.
2. ü™¢ *Concatenator*: Concatena el *output* del modelo con el test inicial.
3. ‚öôÔ∏è *Runner*: Ejecutar la concatenaci√≥n y devuelve un *output*.

### Pseudo-c√≥digo

```shell
System.generateCodeFrom(specs) ‚Üí (GeneratedCode, Stdout/Stderr)
  ‚Üí LLM.send(specs) ‚Üí GeneratedCode
  ‚Üí Concatenator.concatenate(GeneratedCode, Specs) ‚Üí Concatenated
  ‚Üí SwiftRunner.run(Concatenated) ‚Üí Stdout/Stderr
  ‚Üí Exit
```

Al final, termin√© con algunos componentes de m√°s. Concretamente:

- Un iterador (para salir del ciclo tras "N" intentos fallidos o al satisfacer una condici√≥n)
- Algunos *helpers* de gesti√≥n de archivos
- Un almacenador de contexto (para enviar los resultados fallidos al modelo)

![system diagram](images/system.png)

### CLI

```shell
$ tddbuddy \
  --input spec.swift |
  --ouptput specs.output.swift
  --iterations 5
```
-->

## Demo en l√≠nea

Escribe las pruebas unitarias a la derecha y dale a play. Puedes usar `assertEqual` como mini-framework de testing.
[C√≥digo fuente del playground](https://github.com/crisfeim/crisfe.im/tree/main/content/posts/2025.05.13.making-the-ai-suffer-so-you-dont-have-to/codegen-demo)

{{< fragment "codegen-demo/dist/index.html" >}}

## Problemas

Aunque no he tenido la oportunidad de probar exhaustivamente este enfoque como me gustar√≠a, recopil√© algunos ejemplos de problem√°ticas que me encontr√© en mis pruebas.

### Cuando Codestral te da una palmadita y te dice: ‚Äúte dejo el resto como ejercicio, campe√≥n‚Äù

Partiendo de estas *specs*:

```swift
func test_fetch_reposWithMinimumStarsFromRealApi() async throws {
  let sut = GithubClient()
  // This MUST PERFORM A REAL CALL TO THE GITHUB API
  let repos = try await sut.fetchRepositories(minStars: 100)
  assert(!repos.isEmpty)
  assert(repos.allSatisfy { $0.stars >= 100 })
}
```

*Codestral* fue capaz de generar un cliente **funcional**, a pesar de algunas dificultades iniciales:

```swift
struct Repository: Decodable {
  let name: String
  let stargazers_count: Int
  var stars: Int { stargazers_count }
}

class GithubClient {
  func fetchRepositories(minStars: Int) async throws -> [Repository] {
    let url = URL(string: "https://api.github.com/search/repositories?q=stars:>\(minStars)&sort=stars")!
    let (data, _) = try await URLSession.shared.data(from: url)
    let results = try JSONDecoder().decode(SearchResults<Repository>.self, from: data)
    return results.items
  }
}

struct SearchResults<T: Decodable>: Decodable {
  let items: [T]
}
```

Pero tuve que insistir en que hiciese una petici√≥n real [^5]... El modelo se empe√±aba en generarme c√≥digo de este tipo:

```swift
class GithubClient {
  func fetchRepositories(minStars: Int) async throws -> [Repository] {
  /* YOUR IMPLEMENTATION HERE */
  return []
  }
}
```

~~Gracias, Codestral. Con eso y un croquis, ya casi tengo un sistema distribuido.~~

### Cuando el modelo no resuelve el problema... porque ya sabe la respuesta

Aunque poco frecuente, otro caso que me encontr√© ocasionalmente, fue el de pruebas satisfechas *"en duro"*. Ej:

```swift
func test_adder() {
  let sut = Adder(1,3)
  assert(sut.result == 4)
}
```

El modelo generaba esto:

```swift
struct Adder {
  let result = 4
  init (_ a: Int, _ b: Int) {}
}
```

Estos casos se solucionan f√°cilmente a√±adiendo m√°s aserciones a la prueba [indicarle amablemente al modelo que generalice](images/hardcode-again.jpg).

```swift
func test_adder() {
  var sut = Adder(1,3)
  assert(sut.result == 4)

  sut = Adder(3, 4)
  assert(sut.result == 7)

  sut = Adder(5, 4)
  assert(sut.result == 9)
}
```

### Cuando *Gemini* quiere ser tu profe, pero t√∫ solo quieres compilar

En [mi system prompt](sysprompt.txt), el siguiente apartado es importante para que el c√≥digo pueda compilar correctamente:

> Provide ONLY runnable Swift code. No explanations, comments, or formatting (no code blocks, markdown, symbols, or text).

A√∫n con este *prompt*, algunos modelos, ~~ejem ejem *Gemini*~~, ten√≠an dificultades respetando las instrucciones y se empe√±aban en encapsular el c√≥digo en bloques de c√≥digo de markdown, acompa√±√°ndolo adem√°s de comentarios explicativos.

Aunque se agradece el entusiasmo por la pedagog√≠a, hubiera preferido no tener que escribir una funci√≥n de preprocesamiento para limpiar los artefactos de las respuestas.

En la [reescritura del proyecto](https://github.com/crisfeim/cli-tddbuddy), he usado unicamente *Llama 3.2*. Por el momento ~~no he tenido que ponerle cinta adhesiva en la boca.~~ no me he encontrado con este problema.

## Conclusiones

A pesar de las limitaciones descritas y de que mis pruebas han sido bastante modestas, intuyo que es un enfoque prometedor y que se har√° un hueco en la industria a medida de que las herramientas se sofistiquen y las empresas inviertan en este enfoque.

¬øQui√©n sabe? Puede que llegue el d√≠a en que nuestra profesi√≥n como ingenieros de software se reduzca a escribir *especificaciones*.

Creo que el reto real es integrar esta metodolog√≠a en un *tooling* existente (*Xcode, por ejemplo*). Dada la simplicidad del enfoque, dir√≠a que es m√°s bien un reto de experiencia de usuario, que de implementaci√≥n.

Por otro lado, me hubiera gustado integrar un framework de testing real [^2] y recabar datos cuantitativos (n√∫mero de iteraciones necesarias para resolver "X" problema, problemas m√°s complejos, comparaci√≥n entre modelos, etc), pero en esta primera iteraci√≥n, prefer√≠ centrarme en una prueba de concepto funcional.


[^1]: A m√≠ y [a otro pu√±ado de gente](https://github.com/crisfeim/cli-tddbuddy/search?q=tdd&type=code).
[^2]: *XCTest* / *Swift Testing*
[^5]: De ah√≠ el comentario desesperado en may√∫sculas dentro del c√≥digo: *"This MUST PERFORM A REAL CALL TO THE GITHUB API"*
[^8]: El compilador no acepta un *string* como entrada.
